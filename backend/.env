# llama-cpp-python install, currently using dllama-cublas from nvidia because my computer uses nvidia gpu
# REQUIRED for GPU offloading to work, monitor cpu/gpu usage when running to verify
# AMD GPUs likely need to use CLBlast https://github.com/lperezmo/clblast-llama-cpp-python , instructions here but unverified

## UNCOMMENT IF WINDOWS PLATFORM + NVIDIA GPU:
# CMAKE_ARGS="-DLLAMA_CUBLAS=on"
# FORCE_CMAKE=1